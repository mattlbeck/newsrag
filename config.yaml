# platform on which model inference is made
# ollama for local inference using the ollama app
# hg_api for huggingface API inference
inference_platform: hg_api 

# model ID used for the generator
ollama_generator_model: llama3.2
hg_generator_model: meta-llama/Llama-3.2-1B-Instruct

# model used for embeddings
embedder_platform: hg_api
embedder_model: sentence-transformers/all-mpnet-base-v2